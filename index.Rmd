---
title: "Practical machine Learning Course Project"
author: "DM"
date: "09/07/2021"
output: 
  html_document: 
    keep_md: yes
---

## Introductiom

This document covers the week 4 assignment for the practical machine learning course on coursera, the aim of which is to develop a model in order to predict the manner in which people performed a particular exercise (classe variable) from provided datasets.


## Loading data and libraries

All relevant libraries are first loaded and then the training and test data sets are imported from csv files and assigned to separate data frames. This process assumes that the .csv files have already been downloaded and placed in the current working directory.

```{r Load, warning=FALSE,message=FALSE}
library(plotly)
library(corrplot)
library(rpart)
library(caret)
library(rattle)
library(randomForest)

trainingdataraw <- read.csv("pml-training.csv")
testdataraw <- read.csv("pml-testing.csv")
```

## Cleaning data

The training data set is then cleaned in order to remove unnecessary/undesirable variables. The first 5 columns are removed from the data as these only serve as identifiers. Any columns which contain 'NA' values are then removed, followed by any which contain very near-zero values. This leaves a total of 54 columns out of the original 160.
The imported 'test' data set remains unchanged as this will be used once the best fit model is determined to provide the final predictions shown at the end of this document.

```{r Cleaning, warning=FALSE,message=FALSE}
#Remove first 5 ID columns
trainingdata <- trainingdataraw[,-(1:5)]
#Evaluate all NA's and remove columns
trainingdata <- trainingdata[!unlist(vapply(trainingdata, anyNA, logical(1)))]
#Evaluate all near-zero's and remove columns
removedcols <- nearZeroVar(trainingdata, names=TRUE)
namestraining <- names(trainingdata)
trainingdata <- trainingdata[, setdiff(namestraining, removedcols)]
```

Note that the number of variables has now been reduced from the original 160 to 54

## Splitting data

Once cleaned, the training dataset is split into 2 different sizings, a 'training' and a 'test' sample split by a 70/30 ratio from its original size. 

```{r Split, warning=FALSE,message=FALSE}
#Partition data according to recommended sizings (70/30)
trainsplit <- createDataPartition(trainingdata$classe, p =0.7, list=FALSE)
trainingset <- trainingdata[trainsplit,]
testset <- trainingdata[-trainsplit,]
```

The 'test' data created by splitting the loaded training set is only used to evaluate the models accuracy for each approach and is not the same as the loaded in 'test' set which will be used in the final section once the best model has been determined.

## Correlation check

A correlation check is performed between the remaining 54 variables to ensure that there is not a significant amount of correlation between variables which could affect the models accuracy.

```{r Check, warning=FALSE,message=FALSE}
#correlation check
x <- as.numeric(ncol(trainingset))
cormatrix <- cor(trainingset[,-x])
corrplot(cormatrix, method="circle")
```

The plot of the correlation matrix shows that there is only a small amount of correlation present and so it is acceptable to use all remaining variables to determine the 'classe' variable for each modelling approach

## Decision tree model

A decision tree model was created and the confusion matrix shown below along with a visual representation of the decision tree itself, generated by using rattle and fancyRpartPlot:

```{r Decision, warning=FALSE,message=FALSE}
# Create decision tree model
DTmodel <- rpart(classe ~ ., data=trainingset, method="class")
fancyRpartPlot(DTmodel)
predictDT <- predict(DTmodel, newdata=testset, type="class")
confDT <- confusionMatrix(table(predictDT, testset$classe))
confDT
```

The accuracy of the decision tree model was 0.7324.

## Random forest model

A random forest model was then created:

```{r Random, warning=FALSE,message=FALSE}
# Create random forest model
RFcontrol <- trainControl(method = "cv", number = 5, verboseIter = FALSE)
RFmodel <- train(classe ~ ., data=trainingset, method = "rf", trControl = RFcontrol, verbose = FALSE)
predictRF <- predict(RFmodel, newdata = testset)
confRF <- confusionMatrix(table(predictRF, testset$classe))
confRF
```

The accuracy of the random forest model was 0.998, a notable imporvement over the previously generated decision tree.

## Boosted model

Finally, a general boosted model was created:

```{r Boosted, warning=FALSE,message=FALSE}
# Create general boosted model
GBMcontrol <- trainControl(method = "repeatedcv", number = 5)
GBMmodel <- train(classe ~ ., data = trainingset, method = "gbm", trControl = GBMcontrol, verbose = FALSE)
predictGBM <- predict(GBMmodel, newdata = testset)
confGBM <- confusionMatrix(table(predictGBM, testset$classe))
confGBM
```

The boosted model had an accuracy of 0.9847, an improvement over the decision tree model, but slightly worse than the random forest model.

## Application of model to test data set

Out of the 3 develop[ed models, the random forest model had the highest accuracy. This model was the used along with the original loaded in test data to give the final classe variable predictions for 20 cases, as shown below:

```{r Final, warning=FALSE,message=FALSE}
#apply best model to test data set
finalresults <- predict(RFmodel, newdata = testdataraw)
finalresults
```

## End of document